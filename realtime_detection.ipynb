{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Mask R-CNN\n",
    "import sys\n",
    "import numpy as np\n",
    "import skimage\n",
    "import time\n",
    "import os\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"mrcnn\"))\n",
    "from mrcnn import utils, visualize\n",
    "from imutils.video import WebcamVideoStream\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import mold_image\n",
    "\n",
    "# Root directory of the project\n",
    "from samples.coco.coco import CocoConfig\n",
    "\n",
    "\n",
    "\n",
    "# To find local version# Directory to save logs and trained model\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))\n",
    "\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"models\", \"mask_rcnn_coco.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cards on bo dataset size: 85\n"
     ]
    }
   ],
   "source": [
    "ANNOTATION_FILE = os.path.join(ROOT_DIR, \"datasets\", \"labels_cards_in_box_COCO.json\")\n",
    "DATASET_IMG_DIR = os.path.join(ROOT_DIR, \"datasets\", \"cards_in_box_resized_renamed\")\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "class CardsOnBoxDataset(utils.Dataset):\n",
    "\n",
    "  def extract_mask(self, image_id):\n",
    "    with open(ANNOTATION_FILE) as f:\n",
    "      labels = json.load(f)\n",
    "    # masks (stored as annotations in COCO format)\n",
    "    annotations = labels['annotations']\n",
    "    classes = labels['categories']\n",
    "    images = labels['images']\n",
    "    id_coco_file = image_id\n",
    "    image = next((image for image in images if image[\"id\"] == id_coco_file))\n",
    "\n",
    "    image_height = image['height'] #// 4\n",
    "    image_width = image['width'] #// 4\n",
    "\n",
    "    # list containing all the masks of the image of the given id/index\n",
    "    image_masks = list()\n",
    "\n",
    "    # image = next((image for image in images if image[\"id\"] == image_id))\n",
    "    image_annotations = list((annotation for annotation in annotations if annotation[\"image_id\"] == id_coco_file))\n",
    "\n",
    "    segmentation_tuples = list()\n",
    "    class_ids = list()\n",
    "\n",
    "    # only used for drawing\n",
    "    empty_mask = np.zeros((image_height,image_width))\n",
    "    # actual list of masks\n",
    "    concatenated_mask = np.zeros((image_height,image_width, len(image_annotations)))\n",
    "\n",
    "    # for each mask (annotation) belonging to the image we draw it and stack them in masks\n",
    "    for i, annotation in enumerate(image_annotations):\n",
    "\n",
    "      # mask_class = next((mask_class['name'] for mask_class in classes if mask_class[\"id\"] == image_annotations[0]['category_id']))\n",
    "\n",
    "      # orignal list contains a succession of x and y coordinates\n",
    "      # we reshape that to obtain a list of x,y tuples\n",
    "      class_ids.append(annotation['category_id'])\n",
    "      segmentation_tuples = np.reshape(np.array(annotation[\"segmentation\"][0]), (int(np.array(annotation[\"segmentation\"][0]).size/2), 2))\n",
    "      img_to_draw_on = Image.fromarray(empty_mask)\n",
    "      draw = ImageDraw.Draw(img_to_draw_on)\n",
    "      draw.polygon([tuple(p) for p in segmentation_tuples], fill=1)\n",
    "      mask = np.asarray(img_to_draw_on)\n",
    "\n",
    "      concatenated_mask[:, :, i] = mask\n",
    "\n",
    "    return concatenated_mask.astype('bool_'), image_width, image_height, np.asarray(class_ids, dtype=np.int32)\n",
    "\n",
    "  def load_cards_on_box_dataset(self):\n",
    "    # Add classes\n",
    "    self.add_class(\"cards_on_box_dataset\", 1, \"green_card\")\n",
    "    self.add_class(\"cards_on_box_dataset\", 2, \"gold_card\")\n",
    "\n",
    "    for filename in os.listdir(DATASET_IMG_DIR):\n",
    "\n",
    "      image_id = filename[:-4]\n",
    "\n",
    "      # if is_train and int(image_id) in [ 11,  15, 188, 187, 319, 322,  35,  67,  81,  89, 127, 234, 267, 232,  84, 88,\n",
    "      #                                     3,   7, 257, 275, 222, 194, 115, 100, 230, 112, 142, 259, 226, 223, 222, 258,\n",
    "      #                                   244, 272, 159, 120,   9,   2, 137,  28,  19,  23, 204, 310, 312, 303, 237, 190, ]:\n",
    "      #   continue\n",
    "\n",
    "      # if not is_train and int(image_id) not in [ 11,  15, 188, 187, 319, 322,  35,  67,  81,  89, 127, 234, 267, 232,  84, 88,\n",
    "      #                                             3,   7, 257, 275, 222, 194, 115, 100, 230, 112, 142, 259, 226, 223, 222, 258,\n",
    "      #                                           244, 272, 159, 120,   9,   2, 137,  28,  19,  23, 204, 310, 312, 303, 237, 190, ]:\n",
    "      #   continue\n",
    "\n",
    "      img_path = os.path.join(DATASET_IMG_DIR, filename)\n",
    "\n",
    "\n",
    "      self.add_image('cards_on_box_dataset', image_id=image_id, path=img_path, annotation=ANNOTATION_FILE)\n",
    "\n",
    "\n",
    "\n",
    "  def image_reference(self, image_id):\n",
    "    info = self.image_info[image_id]\n",
    "    return info['path']\n",
    "\n",
    "\n",
    "  def load_mask(self, image_id):\n",
    "    info = self.image_info[image_id]\n",
    "\n",
    "    mask , w, h, class_ids= self.extract_mask(int(info['id']))\n",
    "\n",
    "    return mask, class_ids\n",
    "\n",
    "  def load_image(self, image_id):\n",
    "    image = skimage.io.imread(self.image_info[image_id]['path'])\n",
    "\n",
    "    return image\n",
    "\n",
    "cards_on_box_dataset = CardsOnBoxDataset()\n",
    "cards_on_box_dataset.load_cards_on_box_dataset()\n",
    "cards_on_box_dataset.prepare()\n",
    "print('Cards on bo dataset size: %d' % len(cards_on_box_dataset.image_ids))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()# Create model object in inference mode."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\etien\\anaconda3\\envs\\tf-gpu0\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:492: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\etien\\anaconda3\\envs\\tf-gpu0\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:63: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\etien\\anaconda3\\envs\\tf-gpu0\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3630: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\etien\\anaconda3\\envs\\tf-gpu0\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3458: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\etien\\anaconda3\\envs\\tf-gpu0\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1822: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\etien\\anaconda3\\envs\\tf-gpu0\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1208: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\etien\\anaconda3\\envs\\tf-gpu0\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1242: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From A:\\documents\\__PERSO\\Pycharm_projects\\MaskRCNN_realtime_webcam_detection\\mrcnn\\model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\documents\\__PERSO\\Pycharm_projects\\MaskRCNN_realtime_webcam_detection\\mrcnn\\model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From A:\\documents\\__PERSO\\Pycharm_projects\\MaskRCNN_realtime_webcam_detection\\mrcnn\\model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From A:\\documents\\__PERSO\\Pycharm_projects\\MaskRCNN_realtime_webcam_detection\\mrcnn\\model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\documents\\__PERSO\\Pycharm_projects\\MaskRCNN_realtime_webcam_detection\\mrcnn\\model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\documents\\__PERSO\\Pycharm_projects\\MaskRCNN_realtime_webcam_detection\\mrcnn\\model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\etien\\anaconda3\\envs\\tf-gpu0\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:158: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\etien\\anaconda3\\envs\\tf-gpu0\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:163: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\etien\\anaconda3\\envs\\tf-gpu0\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:168: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\etien\\anaconda3\\envs\\tf-gpu0\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:172: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\etien\\anaconda3\\envs\\tf-gpu0\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\etien\\anaconda3\\envs\\tf-gpu0\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:188: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)# Define COCO Class names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loading done\n",
      "Time elapsed: 122.53 second(s)\n",
      "Mean detection time: 1.44 second\n"
     ]
    }
   ],
   "source": [
    "# Time the detection\n",
    "nb_images = 85\n",
    "images = []\n",
    "for image_id in range(nb_images):\n",
    "  image_raw = cards_on_box_dataset.load_image(image_id)\n",
    "  image = mold_image(image_raw, config)\n",
    "  images.append(image)\n",
    "\n",
    "print(\"Image loading done\")\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(nb_images):\n",
    "  _ = model.detect([images[i]], verbose=0)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Time elapsed: {round(end_time - start_time, 2)} second(s)')\n",
    "print(f'Mean detection time: {round((end_time - start_time)/nb_images, 2)} second')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    " 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    " 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    " 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    " 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    " 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    " 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    " 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    " 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    " 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    " 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    " 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    " 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    " 'teddy bear', 'hair drier', 'toothbrush']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Open webcam at the ID 0\n",
    "cap = cv2.VideoCapture(0)#Check whether user selected camera is opened successfully.\n",
    "if not (cap.isOpened()):\n",
    "    print(\"Could not open video device\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A:\\documents\\__PERSO\\Pycharm_projects\\MaskRCNN_realtime_webcam_detection\\mrcnn\\visualize.py:110: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  _, ax = plt.subplots(1, figsize=figsize)\n"
     ]
    }
   ],
   "source": [
    "# Real-Time Webcam Object Detection\n",
    "colors = visualize.random_colors(len(class_names))\n",
    "gentle_grey = (45, 65, 79)\n",
    "white = (255, 255, 255)\n",
    "OPTIMIZE_CAM = False\n",
    "SHOW_FPS = False\n",
    "SHOW_FPS_WO_COUNTER = True # faster\n",
    "PROCESS_IMG = True\n",
    "fps_caption = \"Undefined\"\n",
    "\n",
    "if OPTIMIZE_CAM:\\\n",
    "    vs = WebcamVideoStream(src=0).start()\n",
    "else:\n",
    "    vs = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "if SHOW_FPS:\n",
    "    fps_caption = \"FPS: 0\"\n",
    "    fps_counter = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "SCREEN_NAME = \"Real-Time Webcam\"\n",
    "cv2.namedWindow(SCREEN_NAME, cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty(SCREEN_NAME, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "# Capture frame-by-frame\n",
    "while True:\n",
    "    if OPTIMIZE_CAM:\n",
    "        frame = vs.read()\n",
    "    else:\n",
    "        grabbed, frame = vs.read()\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    if SHOW_FPS_WO_COUNTER:\n",
    "        start_time = time.time() # start time of the loop\n",
    "\n",
    "    if PROCESS_IMG:\n",
    "        results = model.detect([frame])\n",
    "        r = results[0]# Run detection\n",
    "\n",
    "        masked_image = visualize.display_instances(frame, r['rois'], r['masks'],\n",
    "                                                     r['class_ids'], class_names,\n",
    "                                                     r['scores'], colors=colors)\n",
    "\n",
    "        # masked_image = visualize.display_instances_10fps(frame, r['rois'], r['masks'],\n",
    "        #                                              r['class_ids'], class_names,\n",
    "        #                                              r['scores'], colors=colors,\n",
    "        #                                              real_time=True)\n",
    "\n",
    "\n",
    "    if PROCESS_IMG:\n",
    "        s = masked_image\n",
    "    else:\n",
    "        s = frame\n",
    "    # print(\"Image shape: {1}x{0}\".format(s.shape[0], s.shape[1]))\n",
    "    #\n",
    "\n",
    "    width = frame.shape[1]\n",
    "    height = frame.shape[0]\n",
    "    top_left_corner = (width-120, height-20)\n",
    "    bott_right_corner = (width, height)\n",
    "    top_left_corner_cvtext = (width-80, height-5)\n",
    "\n",
    "    if SHOW_FPS:\n",
    "        fps_counter+=1\n",
    "        if (time.time() - start_time) > 5 : # every 5 second\n",
    "            print('')\n",
    "            # I commented that\n",
    "            # fps_caption = \"FPS: {:.0f}\".format(fps_counter / (time.time() - start_time))\n",
    "            # print(fps_caption)\n",
    "\n",
    "    fps_counter = 0\n",
    "    start_time = time.time()\n",
    "    ret, baseline = cv2.getTextSize(fps_caption, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    cv2.rectangle(s, (width - ret[0], height - ret[1] - baseline),\n",
    "                  bott_right_corner, gentle_grey, -1)\n",
    "    cv2.putText(s,fps_caption, (width - ret[0], height - baseline),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, white, lineType=cv2.LINE_AA)\n",
    "\n",
    "    if SHOW_FPS_WO_COUNTER:\n",
    "        # Display the resulting frame\n",
    "        # fps_caption = \"FPS: {:.0f}\".format(1.0 / (time.time() - start_time))\n",
    "        # print(\"FPS: \", 1.0 / (time.time() — start_time))\n",
    "        # Put the rectangle and text on the bottom left corner\n",
    "        ret, baseline = cv2.getTextSize(fps_caption, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        cv2.rectangle(s, (width - ret[0], height - ret[1] - baseline),\n",
    "                      bott_right_corner, gentle_grey, -1)\n",
    "        cv2.putText(s, fps_caption, (width - ret[0], height - baseline),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, white, 1, lineType=cv2.LINE_AA)#Display the frame\n",
    "\n",
    "    # s = cv2.resize(s,(1920,1080))\n",
    "    s = cv2.resize(s,(1920,1080))\n",
    "    cv2.imshow(SCREEN_NAME, s)\n",
    "    cv2.waitKey(1)\n",
    "    # if cv2.waitKey(1) & 0xFF == ord(‘q’):\n",
    "    # break\n",
    "\n",
    "# When everything is done, release the camera from video capture\n",
    "if OPTIMIZE_CAM:\n",
    "    vs.stop()\n",
    "else:\n",
    "    vs.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-91197006",
   "language": "python",
   "display_name": "PyCharm (MaskRCNN_realtime_detection)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}